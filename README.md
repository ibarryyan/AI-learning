## 🚢程序员AI学习指南

![Static Badge](https://img.shields.io/badge/AI%20Learning-闫同学-8A2BE2)
<a href="https://github.com/ibarryyan/golang-tips-100/blob/master/img/wechat.jpg"><img src="https://img.shields.io/badge/%E5%85%AC%E4%BC%97%E5%8F%B7-%E6%89%AF%E7%BC%96%E7%A8%8B%E7%9A%84%E6%B7%A1-blue" alt="公众号"></a>
[![](https://img.shields.io/github/stars/ibarryyan/AI-learning.svg?style=flat)](https://github.com/ibarryyan/AI-learning/stargazers)

收集和整理与AI学习相关的资源，包括但不限于教程、代码示例、论文、书籍推荐等。无论你是AI领域的新手还是有一定经验的开发者，都希望这个仓库能对你有所帮助。

### 🟢开源AI大模型

| 模型            | 链接                                                          | 说明                              | 推荐星级 |
|:------------- |:----------------------------------------------------------- |:------------------------------- |:----:|
| LLaMA2        | [LLaMA2](https://github.com/facebookresearch/llama)         | Meta推出的开源大语言模型，适用于研究与应用。        | ⭐⭐⭐⭐ |
| GPT-J         | [GPT-J](https://github.com/kingoflolz/mesh-transformer-jax) | EleutherAI开发的开源大语言模型，性能接近GPT-3。 | ⭐⭐⭐⭐ |
| Alpaca        | [Alpaca](https://github.com/tatsu-lab/stanford_alpaca)      | 基于LLaMA的指令调优模型，适用于交互式应用。        | ⭐⭐⭐⭐ |
| OpenAssistant | [OpenAssistant](https://github.com/LAION-AI/Open-Assistant) | LAION开发的开源助手模型，注重对话能力。          | ⭐⭐⭐⭐ |
| Vicuna        | [Vicuna](https://github.com/lm-sys/FastChat)                | 基于LLaMA的对话优化模型，适用于交互式应用。        | ⭐⭐⭐⭐ |
| GPT-NeoX      | [GPT-NeoX](https://github.com/EleutherAI/gpt-neox)          | EleutherAI开发的开源大语言模型，支持大规模训练。   | ⭐⭐⭐⭐ |

### 🌐AI大模型产品

| 产品名称      | 网址                                    |
|:--------- |:------------------------------------- |
| DeepSeek  | https://chat.deepseek.com/            | 
| ChatGPT   | https://chat.openai.com/              | 
| Bard      | https://bard.google.com/              | 
| Claude    | https://www.anthropic.com/            | 
| 文心一言      | https://yiyan.baidu.com/              | 
| 通义千问      | https://tongyi.aliyun.com/            | 
| 讯飞星火      | https://xinghuo.xfyun.cn/             | 
| 智谱清言      | https://chatglm.cn/                   | 
| AI文本人性化   | https://humanize.im/zh-CN             | 
| 腾讯元器      | https://yuanqi.tencent.com/agent-shop |
| Napkin    | https://chat01.ai/?ref=nyi8wifx       |
| Chat01.ai | https://www.napkin.ai/                | 

### 🔦教程Tutorial

| 教程              | 链接                                                            | 说明                          | 推荐星级 |
|:--------------- |:------------------------------------------------------------- |:--------------------------- |:----:|
| 面向初学者的人工智能课程    | [Link](https://github.com/microsoft/AI-For-Beginners)         | 微软推出的面向初学者的人工智能课程           | ⭐⭐⭐  |
| LLMCookbook     | [LLMCookbook](https://github.com/datawhalechina/llm-cookbook) | 面向开发者的大模型系列教程，涵盖API使用与应用开发。 | ⭐⭐⭐⭐ |
| Hugging Face 教程 | [Hugging Face](https://huggingface.co/learn)                  | 提供丰富的NLP模型使用与训练教程。          | ⭐⭐⭐  |
| Stanford CS224n | [CS224n](http://web.stanford.edu/class/cs224n/)               | 斯坦福大学的自然语言处理课程，涵盖最新研究进展。    | ⭐⭐⭐⭐ |
| PyTorch 官方教程    | [PyTorch Tutorials](https://pytorch.org/tutorials/)           | 官方提供的PyTorch使用与深度学习教程。      | ⭐⭐⭐  |

### ⛏️项目工具Tools

| 资料名称                      | 链接                                                   | 说明                           | 推荐星级 |
|:------------------------- |:---------------------------------------------------- |:---------------------------- |:----:|
| TensorFlow                | [TensorFlow](https://www.tensorflow.org/)            | Google开发的开源深度学习框架，支持多种平台。    | ⭐⭐⭐⭐ |
| PyTorch                   | [PyTorch](https://pytorch.org/)                      | Facebook开发的深度学习框架，灵活性高，适合研究。 | ⭐⭐⭐⭐ |
| Hugging Face Transformers | [Transformers](https://huggingface.co/transformers/) | 提供丰富的预训练模型与工具，便于NLP任务开发。     | ⭐⭐⭐⭐ |
| OpenCV                    | [OpenCV](https://opencv.org/)                        | 计算机视觉库，提供丰富的图像处理功能。          | ⭐⭐⭐  |

### 📜论文Papers

| 资料名称                                                                                  | 链接                                                                             | 说明                             | 推荐星级 |
|:------------------------------------------------------------------------------------- |:------------------------------------------------------------------------------ |:------------------------------ |:----:|
| 2024年值得注意的人工智能研究论文（一）                                                                 | [Link](https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-1) | 2024年值得注意的人工智能研究论文（一）          | ⭐⭐⭐  |
| Attention Is All You Need                                                             | [论文](https://arxiv.org/abs/1706.03762)                                         | 提出Transformer模型，是现代大语言模型的基础。   | ⭐⭐⭐  |
| BERT: Pre-training of Deep Bidirectional Transformers                                 | [论文](https://arxiv.org/abs/1810.04805)                                         | 提出BERT模型，开启了预训练语言模型的新篇章。       | ⭐⭐⭐  |
| GPT-3: Language Models are Few-Shot Learners                                          | [论文](https://arxiv.org/abs/2005.14165)                                         | 描述GPT-3模型的架构与能力，展示其在多任务中的表现。   | ⭐⭐⭐  |
| Vision Transformer (ViT)                                                              | [论文](https://arxiv.org/abs/2010.11929)                                         | 将Transformer架构应用于计算机视觉任务。      | ⭐⭐   |
| YOLOv4: Optimal Speed and Accuracy                                                    | [论文](https://arxiv.org/abs/2004.10934)                                         | 提出YOLOv4模型，提升了目标检测的速度与准确性。     | ⭐⭐   |
| Reinforcement Learning with Unsupervised Auxiliary Tasks                              | [论文](https://arxiv.org/abs/1611.05397)                                         | 探讨在强化学习中引入辅助任务以提升性能。           | ⭐⭐   |
| Self-Attention Generative Adversarial Networks (SAGAN)                                | [论文](https://arxiv.org/abs/1805.08318)                                         | 在GAN中引入自注意力机制，提升生成效果。          | ⭐⭐   |
| CLIP: Learning Transferable Visual Models                                             | [论文](https://arxiv.org/abs/2103.00020)                                         | 结合图像与文本的对比学习模型，提升多模态理解能力。      | ⭐⭐⭐  |
| AlphaFold: Using AI for Scientific Discovery                                          | [论文](https://www.nature.com/articles/s41586-021-03819-2)                       | DeepMind开发的蛋白质结构预测模型，突破性成果。    | ⭐⭐⭐  |
| Sparse Transformer                                                                    | [论文](https://arxiv.org/abs/1904.10509)                                         | 提出稀疏注意力机制，提升Transformer的效率。    | ⭐⭐⭐  |
| T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | [论文](https://arxiv.org/abs/1910.10683)                                         | 提出T5模型，将所有NLP任务统一为文本到文本的框架。    | ⭐⭐⭐  |
| Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context               | [论文](https://arxiv.org/abs/1901.02860)                                         | 提出Transformer-XL，支持更长上下文的语言模型。 | ⭐⭐⭐  |

### 📖书籍推荐Books

| 教程  | Link | 说明  | 推荐星级 | 备注  |
| --- | ---- | --- | ---- | --- |
|     |      |     |   |     |

## 🤔如何使用How to use

## 😶‍🌫️联系作者

E-mail：yanmingxin.boy@gmail.com

WeChat: 扯编程的淡

![图片描述](assets/wx.png)